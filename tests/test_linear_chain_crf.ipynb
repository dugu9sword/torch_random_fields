{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(IterableDataset):\n",
    "    def __init__(self, length=25) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.length = length\n",
    "\n",
    "        vocab_ = [str(i) for i in range(10)] + [\".\", \"+\", \"-\", \"*\", \"/\", \"=\", \"^\", \"$\", \"@\"]\n",
    "        self.word2idx = {ele: idx for idx, ele in enumerate(vocab_)}\n",
    "        self.idx2word = {idx: ele for idx, ele in enumerate(vocab_)}\n",
    "\n",
    "        vocab_ = [\"B\", \"M\", \"E\", \"S\", \"@\"]\n",
    "        self.label2idx = {ele: idx for idx, ele in enumerate(vocab_)}\n",
    "        self.idx2label = {idx: ele for idx, ele in enumerate(vocab_)}\n",
    "\n",
    "        self.pad = \"@\"\n",
    "\n",
    "    def rand_word(self):\n",
    "        max_num = 10**(self.length // 8)\n",
    "        x = random.randint(0, 1)\n",
    "        ret = \"\"\n",
    "        if x == 1:\n",
    "            ret += \"-\"\n",
    "        else:\n",
    "            ret += \"\"\n",
    "        x = random.randint(0, 3)\n",
    "        if x == 0:\n",
    "            ret += str(random.randint(1, max_num))\n",
    "        elif x == 1:\n",
    "            ret += str(random.randint(1, max_num))\n",
    "            ret += \".\"\n",
    "        elif x == 2:\n",
    "            ret += str(random.randint(1, max_num))\n",
    "            ret += \".\"\n",
    "            ret += str(random.randint(1, max_num))\n",
    "        else:\n",
    "            ret += \".\"\n",
    "            ret += str(random.randint(1, max_num))\n",
    "        return ret\n",
    "\n",
    "    def label_from_length(self, num):\n",
    "        if num == 1:\n",
    "            return \"S\"\n",
    "        else:\n",
    "            return \"B\" + \"M\" * (num - 2) + \"E\"\n",
    "\n",
    "    def generate(self):\n",
    "        x1 = self.rand_word()\n",
    "        x2 = self.rand_word()\n",
    "        y = self.rand_word()\n",
    "        op = \"+-*/\"[random.randint(0, 3)]\n",
    "        sent = [\"^\", x1, op, x2, \"=\", y, \"$\"]\n",
    "        label = [self.label_from_length(len(ele)) for ele in sent]\n",
    "        sent = \"\".join(sent)\n",
    "        sent += (self.length - len(sent)) * self.pad\n",
    "        label = \"\".join(label)\n",
    "        label += (self.length - len(label)) * self.pad\n",
    "        sent = torch.tensor([self.word2idx[ele] for ele in sent])\n",
    "        label = torch.tensor([self.label2idx[ele] for ele in label])\n",
    "        masks = sent != self.word2idx[self.pad]\n",
    "        return sent, masks, label\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield self.generate()\n",
    "\n",
    "dataset = PseudoDataset(length=75)\n",
    "train_data = DataLoader(dataset, batch_size=20)\n",
    "test_data = DataLoader(dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [00:01<00:00, 159.37it/s]\n",
      "100%|██████████| 301/301 [00:01<00:00, 162.33it/s]\n",
      "100%|██████████| 301/301 [00:03<00:00, 77.85it/s]\n",
      "100%|██████████| 301/301 [00:06<00:00, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== cost ======\n",
      "iteration            100    200    300\n",
      "-----------------  -----  -----  -----\n",
      "piecewise          0.597  0.614  0.661\n",
      "pseudo-likelihood  0.599  0.669  0.571\n",
      "perceptron         1.267  1.342  1.241\n",
      "exact-likelihood   2.237  2.361  2.208\n",
      "====== accu ======\n",
      "iteration            100    200    300\n",
      "-----------------  -----  -----  -----\n",
      "piecewise          0.795  0.816  0.847\n",
      "pseudo-likelihood  0.681  0.840  0.855\n",
      "perceptron         0.287  0.370  0.496\n",
      "exact-likelihood   0.285  0.708  0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from torch_random_fields.models import LinearChainCRF\n",
    "from torch_random_fields.models.constants import Inference, Training\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(num_embeddings=len(dataset.word2idx), embedding_dim=10)\n",
    "        self.pred = torch.nn.Linear(10, len(dataset.label2idx))\n",
    "        self.crf = LinearChainCRF(\n",
    "            len(dataset.label2idx),\n",
    "            low_rank=5,\n",
    "            training=Training.PIECEWISE,\n",
    "            inference=Inference.VITERBI,\n",
    "            feature_size=10,\n",
    "        )\n",
    "\n",
    "    def forward(self, nodes, masks, targets):\n",
    "        feats = self.embed(nodes)\n",
    "        unaries = self.pred(feats)\n",
    "        loss = self.crf(unaries=unaries, targets=targets, masks=masks, node_features=feats)\n",
    "        return loss\n",
    "\n",
    "    def decode(self, nodes, masks):\n",
    "        unaries = self.pred(self.embed(nodes))\n",
    "        return self.crf(unaries, masks=masks, node_features=None)[1]\n",
    "\n",
    "    def evaulate(self, nodes, masks, targets):\n",
    "        pred = self(nodes, masks, None)[1]\n",
    "        pred.masked_fill_(~masks, dataset.label2idx[dataset.pad])\n",
    "        corr = pred == targets\n",
    "        accu = corr[masks].sum() / masks.sum()\n",
    "        return accu\n",
    "\n",
    "\n",
    "cost_table = []\n",
    "accu_table = []\n",
    "\n",
    "for training in [Training.PIECEWISE, Training.PSEUDO_LIKELIHOOD, Training.PERCEPTRON, Training.EXACT_LIKELIHOOD]:\n",
    "# for training in [Training.PERCEPTRON]:\n",
    "    cost_table.append([training])\n",
    "    accu_table.append([training])\n",
    "\n",
    "    model = Model()\n",
    "    model.crf.training = training\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    last_time = time.time()\n",
    "    for i in tqdm(range(301)):\n",
    "        nodes, masks, targets = next(iter(train_data))\n",
    "        loss = model(nodes, masks, targets)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            current_time = time.time()\n",
    "            cost_time = current_time - last_time\n",
    "            last_time = current_time\n",
    "            accu = model.evaulate(*next(iter(test_data)))\n",
    "            cost_table[-1].append(cost_time)\n",
    "            accu_table[-1].append(accu)\n",
    "\n",
    "headers = [\"iteration\"] + [str(i * 100) for i in range(1, len(cost_table[0]) + 1)]\n",
    "print(\"====== cost ======\")\n",
    "print(tabulate(cost_table, headers=headers, floatfmt=\".3f\"))\n",
    "print(\"====== accu ======\")\n",
    "print(tabulate(accu_table, headers=headers, floatfmt=\".3f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 701/701 [00:04<00:00, 155.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== cost ======\n",
      "iteration           100    200    300    400    500    600    700\n",
      "----------------  -----  -----  -----  -----  -----  -----  -----\n",
      "viterbi           0.064  0.017  0.017  0.017  0.017  0.019  0.017\n",
      "batch-mean-field  0.016  0.014  0.014  0.014  0.014  0.015  0.014\n",
      "====== accu ======\n",
      "iteration           100    200    300    400    500    600    700\n",
      "----------------  -----  -----  -----  -----  -----  -----  -----\n",
      "viterbi           0.848  0.871  0.894  0.909  0.934  0.959  0.969\n",
      "batch-mean-field  0.850  0.877  0.888  0.930  0.955  0.962  0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cost_table = []\n",
    "accu_table = []\n",
    "\n",
    "INFERENCE_METHODS = [Inference.VITERBI, Inference.BATCH_MEAN_FIELD]\n",
    "for inference in INFERENCE_METHODS:\n",
    "    cost_table.append([inference])\n",
    "    accu_table.append([inference])\n",
    "\n",
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in tqdm(range(701)):\n",
    "    nodes, masks, targets = next(iter(train_data))\n",
    "    loss = model(nodes, masks, targets)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if i > 0 and i % 100 == 0:\n",
    "        for inference in INFERENCE_METHODS:\n",
    "            last_time = time.time()\n",
    "            model.crf.inference = inference\n",
    "            accu = model.evaulate(*next(iter(test_data)))\n",
    "            cost_time = time.time() - last_time\n",
    "\n",
    "            cost_table[INFERENCE_METHODS.index(inference)].append(cost_time)\n",
    "            accu_table[INFERENCE_METHODS.index(inference)].append(accu)\n",
    "\n",
    "headers = [\"iteration\"] + [str(i * 100) for i in range(1, len(cost_table[0]) + 1)]\n",
    "print(\"====== cost ======\")\n",
    "print(tabulate(cost_table, headers=headers, floatfmt=\".3f\"))\n",
    "print(\"====== accu ======\")\n",
    "print(tabulate(accu_table, headers=headers, floatfmt=\".3f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pystruct3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26e7100929c5974aafe5d65382914e883abf933defba9fccc362b643f50b42c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
