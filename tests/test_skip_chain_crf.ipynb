{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(IterableDataset):\n",
    "    def __init__(self, length, skip_as_ternary) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.length = length\n",
    "        self.skip_as_ternary = skip_as_ternary\n",
    "\n",
    "        vocab_ = \"ABCDEFG1234567_@\"\n",
    "        self.word2idx = {ele: idx for idx, ele in enumerate(vocab_)}\n",
    "        self.idx2word = {idx: ele for idx, ele in enumerate(vocab_)}\n",
    "\n",
    "        vocab_ = \"ABCDEFG_@\"\n",
    "        self.label2idx = {ele: idx for idx, ele in enumerate(vocab_)}\n",
    "        self.idx2label = {idx: ele for idx, ele in enumerate(vocab_)}\n",
    "\n",
    "        self.pad = \"@\"\n",
    "\n",
    "    def generate(self):\n",
    "        seqlen = random.randint(int(self.length * 0.6), self.length)\n",
    "        sent = list(\"_\" * seqlen + self.pad * (self.length - seqlen))\n",
    "        label = list(\"_\" * seqlen + self.pad * (self.length - seqlen))\n",
    "        names = list(\"ABCDEFG\")\n",
    "        random.shuffle(names)\n",
    "        names = names[:3]\n",
    "        nicks = list(\"1234567\")\n",
    "        random.shuffle(nicks)\n",
    "        nicks = nicks[:3]\n",
    "        locs = list(range(seqlen))\n",
    "        random.shuffle(locs)\n",
    "\n",
    "        bin_edges = [(i, i+1) for i in range(seqlen - 2)]\n",
    "        ter_edges = []\n",
    "        for i in range(3):\n",
    "            loc1 = locs.pop()\n",
    "            while loc1 - 1 not in locs:\n",
    "                locs.insert(0, loc1)\n",
    "                loc1 = locs.pop()\n",
    "            locs.remove(loc1 - 1)\n",
    "            loc2 = locs.pop()\n",
    "            loc3 = locs.pop()\n",
    "            sent[loc1 - 1] = names[i]\n",
    "            sent[loc1], sent[loc2], sent[loc3] = nicks[i], nicks[i], nicks[i]\n",
    "            label[loc1], label[loc2], label[loc3] = names[i], names[i], names[i]\n",
    "\n",
    "            if not self.skip_as_ternary:\n",
    "                bin_edges.append((loc1, loc2))\n",
    "                bin_edges.append((loc2, loc3))\n",
    "                bin_edges.append((loc1, loc3))\n",
    "            else:\n",
    "                ter_edges.append((loc1, loc2, loc3))\n",
    "        \n",
    "        bin_edges_real_len = len(bin_edges)\n",
    "        bin_edges.extend([(0, 0) for _ in range(self.length - seqlen)])\n",
    "\n",
    "        sent = \"\".join(sent)\n",
    "        label = \"\".join(label)\n",
    "\n",
    "        nodes = torch.tensor([self.word2idx[ele] for ele in sent])\n",
    "        bin_edges = torch.tensor(bin_edges)\n",
    "        ter_edges = torch.tensor(ter_edges)\n",
    "        node_masks = nodes != self.word2idx[self.pad]\n",
    "        bin_edge_masks = torch.zeros([len(bin_edges)]).bool()\n",
    "        bin_edge_masks[:bin_edges_real_len] = True\n",
    "        ter_edge_masks = torch.ones([len(ter_edges)]).bool()\n",
    "        label = torch.tensor([self.label2idx[ele] for ele in label])\n",
    "        return nodes, node_masks, bin_edges, bin_edge_masks, ter_edges, ter_edge_masks, label\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield self.generate()\n",
    "\n",
    "    def to_sent(self, tensor):\n",
    "        sent = [dataset.idx2word[ele] for ele in tensor.view(-1).tolist()]\n",
    "        return \"\".join(sent)\n",
    "\n",
    "    def to_label(self, tensor):\n",
    "        label = [dataset.idx2label[ele] for ele in tensor.view(-1).tolist()]\n",
    "        return \"\".join(label)\n",
    "\n",
    "dataset = PseudoDataset(50, True)\n",
    "dataset.generate()\n",
    "train_data = DataLoader(dataset, batch_size=20)\n",
    "test_data = DataLoader(dataset, batch_size=100)\n",
    "\n",
    "for b in train_data:\n",
    "    nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, label = b\n",
    "    # print(ter_edge_masks)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.8468, accu: 1.0000: : 800it [00:17, 46.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch_random_fields.models import GeneralCRF\n",
    "import einops\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch_random_fields.models.constants import Inference, Training\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(num_embeddings=len(dataset.word2idx), embedding_dim=10)\n",
    "        self.pred = torch.nn.Sequential(\n",
    "            Rearrange(\"B T C -> B C T\"),\n",
    "            torch.nn.Conv1d(10, len(dataset.label2idx), 3, padding=\"same\"),\n",
    "            Rearrange(\"B C T -> B T C\"),\n",
    "        )\n",
    "        # self.pred = torch.nn.Linear(10, len(dataset.label2idx))\n",
    "        self.crf = GeneralCRF(\n",
    "            num_states=len(dataset.label2idx), \n",
    "            feature_size=10, \n",
    "            beam_size=64,\n",
    "            low_rank=10, \n",
    "            training=Training.PIECEWISE, \n",
    "            inference=Inference.BELIEF_PROPAGATION,\n",
    "            support_ternary=True,\n",
    "        )\n",
    "    \n",
    "    def forward(self, nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, targets):\n",
    "        feats = self.embed(nodes)\n",
    "        unaries = self.pred(feats)\n",
    "        loss = self.crf(\n",
    "            unaries=unaries, \n",
    "            masks=masks,\n",
    "            binary_edges=bin_edges,\n",
    "            binary_masks=bin_masks,\n",
    "            ternary_edges=ter_edges,\n",
    "            ternary_masks=ter_masks,\n",
    "            targets=targets,\n",
    "            node_features=feats\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def evaulate(self, nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, label):\n",
    "        for b in test_data:\n",
    "            pred = self(nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, None)[1]\n",
    "            break\n",
    "        corr = pred == label\n",
    "        accu = corr[masks].sum() / masks.sum()\n",
    "        return accu\n",
    "\n",
    "\n",
    "pbar = tqdm(train_data)\n",
    "model = Model()\n",
    "opt = torch.optim.AdamW(model.parameters(), .01, weight_decay=0.01)\n",
    "for i, batch in enumerate(pbar):\n",
    "    nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, label = batch\n",
    "    loss = model(nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, label)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        accu = model.evaulate(nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, label)\n",
    "        pbar.set_description(\"loss: {:.4f}, accu: {:.4f}\".format(loss.item(), accu.item()))\n",
    "    \n",
    "    if i == 800:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32_1__2___C1_____B3__3G2_1__________\n",
      "BG_C__G____C______B__B_G_C__________\n",
      "BG_C__G____C______B__B_G_C__________\n"
     ]
    }
   ],
   "source": [
    "bid = 1\n",
    "node_len = masks[bid].sum()\n",
    "print(dataset.to_sent(nodes[bid, :node_len]))\n",
    "print(dataset.to_label(label[bid, :node_len]))\n",
    "\n",
    "pred = model(nodes, masks, bin_edges, bin_masks, ter_edges, ter_masks, None)[1]\n",
    "print(dataset.to_label(pred[bid, :node_len]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pystruct3.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26e7100929c5974aafe5d65382914e883abf933defba9fccc362b643f50b42c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
